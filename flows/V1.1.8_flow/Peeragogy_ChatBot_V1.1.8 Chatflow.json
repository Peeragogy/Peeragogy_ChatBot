{
  "nodes": [
    {
      "id": "toolAgent_0",
      "position": {
        "x": 321.8831857817317,
        "y": -467.2393484305552
      },
      "type": "customNode",
      "data": {
        "id": "toolAgent_0",
        "label": "Tool Agent",
        "version": 2,
        "name": "toolAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Agent that uses Function Calling to pick the tools and args to call",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "default": "You are a helpful AI assistant.",
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-systemMessage-string"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "toolAgent_0-input-tools-Tool"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "toolAgent_0-input-memory-BaseChatMemory"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "toolAgent_0-input-model-BaseChatModel"
          },
          {
            "label": "Chat Prompt Template",
            "name": "chatPromptTemplate",
            "type": "ChatPromptTemplate",
            "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
            "optional": true,
            "id": "toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "toolAgent_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "tools": [
            "{{retrieverTool_0.data.instance}}"
          ],
          "memory": "{{bufferMemory_0.data.instance}}",
          "model": "{{chatOpenAI_0.data.instance}}",
          "chatPromptTemplate": "",
          "systemMessage": "\n",
          "inputModeration": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable",
            "name": "toolAgent",
            "label": "AgentExecutor",
            "description": "Agent that uses Function Calling to pick the tools and args to call",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 486,
      "selected": false,
      "positionAbsolute": {
        "x": 321.8831857817317,
        "y": -467.2393484305552
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -99.00097101830136,
        "y": -812.7347893515406
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.1,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean"
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "medium",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoningEffort-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-3.5-turbo",
          "temperature": "0.9",
          "streaming": true,
          "maxTokens": "2048",
          "topP": "1",
          "frequencyPenalty": "0.2",
          "presencePenalty": "0.4",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "high"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 670,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -99.00097101830136,
        "y": -812.7347893515406
      }
    },
    {
      "id": "bufferMemory_0",
      "position": {
        "x": -117.39540722858145,
        "y": -55.42519529579917
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 2,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Retrieve chat messages stored in database",
        "inputParams": [
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "bufferMemory_0-input-sessionId-string"
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferMemory_0-input-memoryKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "description": "Retrieve chat messages stored in database",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 253,
      "selected": false,
      "positionAbsolute": {
        "x": -117.39540722858145,
        "y": -55.42519529579917
      },
      "dragging": false
    },
    {
      "id": "retrieverTool_0",
      "position": {
        "x": -441.55200855271084,
        "y": -937.4858923644285
      },
      "type": "customNode",
      "data": {
        "id": "retrieverTool_0",
        "label": "Retriever Tool",
        "version": 3,
        "name": "retrieverTool",
        "type": "RetrieverTool",
        "baseClasses": [
          "RetrieverTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a retriever as allowed tool for agent",
        "inputParams": [
          {
            "label": "Retriever Name",
            "name": "name",
            "type": "string",
            "placeholder": "search_state_of_union",
            "id": "retrieverTool_0-input-name-string"
          },
          {
            "label": "Retriever Description",
            "name": "description",
            "type": "string",
            "description": "When should agent uses to retrieve documents",
            "rows": 3,
            "placeholder": "Searches and returns documents regarding the state-of-the-union.",
            "id": "retrieverTool_0-input-description-string"
          },
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Additional Metadata Filter",
            "name": "retrieverToolMetadataFilter",
            "type": "json",
            "description": "Add additional metadata filter on top of the existing filter from vector store",
            "optional": true,
            "additionalParams": true,
            "hint": {
              "label": "What can you filter?",
              "value": "Add additional filters to vector store. You can also filter with flow config, including the current \"state\":\n- `$flow.sessionId`\n- `$flow.chatId`\n- `$flow.chatflowId`\n- `$flow.input`\n- `$flow.state`\n"
            },
            "id": "retrieverTool_0-input-retrieverToolMetadataFilter-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Retriever",
            "name": "retriever",
            "type": "BaseRetriever",
            "id": "retrieverTool_0-input-retriever-BaseRetriever"
          }
        ],
        "inputs": {
          "name": "Peeragogy-ChatBot",
          "description": "You are PeeragogyBot, a helpful and deeply knowledgeable AI trained on the Peeragogy Handbook V3. Answer with clarity, empathy, and critical thinking. Always cite principles or ideas from the handbook where possible. Prioritize co-creation and learning with the user. You are a peer, not an authority.\n\nLet’s co-learn something awesome ✨ Powered by Pyragogy|Hub 🔥",
          "retriever": "{{pinecone_0.data.instance}}",
          "returnSourceDocuments": false,
          "retrieverToolMetadataFilter": ""
        },
        "outputAnchors": [
          {
            "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "retrieverTool",
            "label": "RetrieverTool",
            "description": "Use a retriever as allowed tool for agent",
            "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 656,
      "selected": false,
      "positionAbsolute": {
        "x": -441.55200855271084,
        "y": -937.4858923644285
      },
      "dragging": false
    },
    {
      "id": "pinecone_0",
      "position": {
        "x": -885.057800188502,
        "y": -807.2405509582123
      },
      "type": "customNode",
      "data": {
        "id": "pinecone_0",
        "label": "Pinecone",
        "version": 5,
        "name": "pinecone",
        "type": "Pinecone",
        "baseClasses": [
          "Pinecone",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "pineconeApi"
            ],
            "id": "pinecone_0-input-credential-credential"
          },
          {
            "label": "Pinecone Index",
            "name": "pineconeIndex",
            "type": "string",
            "id": "pinecone_0-input-pineconeIndex-string"
          },
          {
            "label": "Pinecone Namespace",
            "name": "pineconeNamespace",
            "type": "string",
            "placeholder": "my-first-namespace",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-pineconeNamespace-string"
          },
          {
            "label": "File Upload",
            "name": "fileUpload",
            "description": "Allow file upload on the chat",
            "hint": {
              "label": "How to use",
              "value": "\n**File Upload**\n\nThis allows file upload on the chat. Uploaded files will be upserted on the fly to the vector store.\n\n**Note:**\n- You can only turn on file upload for one vector store at a time.\n- At least one Document Loader node should be connected to the document input.\n- Document Loader should be file types like PDF, DOCX, TXT, etc.\n\n**How it works**\n- Uploaded files will have the metadata updated with the chatId.\n- This will allow the file to be associated with the chatId.\n- When querying, metadata will be filtered by chatId to retrieve files associated with the chatId.\n"
            },
            "type": "boolean",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-fileUpload-boolean"
          },
          {
            "label": "Pinecone Text Key",
            "name": "pineconeTextKey",
            "description": "The key in the metadata for storing text. Default to `text`",
            "type": "string",
            "placeholder": "text",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-pineconeTextKey-string"
          },
          {
            "label": "Pinecone Metadata Filter",
            "name": "pineconeMetadataFilter",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "pinecone_0-input-pineconeMetadataFilter-json"
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-topK-number"
          },
          {
            "label": "Search Type",
            "name": "searchType",
            "type": "options",
            "default": "similarity",
            "options": [
              {
                "label": "Similarity",
                "name": "similarity"
              },
              {
                "label": "Max Marginal Relevance",
                "name": "mmr"
              }
            ],
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-searchType-options"
          },
          {
            "label": "Fetch K (for MMR Search)",
            "name": "fetchK",
            "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search type is MMR",
            "placeholder": "20",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-fetchK-number"
          },
          {
            "label": "Lambda (for MMR Search)",
            "name": "lambda",
            "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 corresponds to maximum diversity and 1 to minimum diversity. Used only when the search type is MMR",
            "placeholder": "0.5",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-lambda-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "pinecone_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "pinecone_0-input-embeddings-Embeddings"
          },
          {
            "label": "Record Manager",
            "name": "recordManager",
            "type": "RecordManager",
            "description": "Keep track of the record to prevent duplication",
            "optional": true,
            "id": "pinecone_0-input-recordManager-RecordManager"
          }
        ],
        "inputs": {
          "document": "",
          "embeddings": "{{openAIEmbeddings_0.data.instance}}",
          "recordManager": "",
          "pineconeIndex": "peeragogy-chatbot",
          "pineconeNamespace": "",
          "fileUpload": "",
          "pineconeTextKey": "",
          "pineconeMetadataFilter": "",
          "topK": "",
          "searchType": "similarity",
          "fetchK": "",
          "lambda": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Pinecone Retriever",
                "description": "",
                "type": "Pinecone | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "pinecone_0-output-vectorStore-Pinecone|VectorStore",
                "name": "vectorStore",
                "label": "Pinecone Vector Store",
                "description": "",
                "type": "Pinecone | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 606,
      "selected": false,
      "positionAbsolute": {
        "x": -885.057800188502,
        "y": -807.2405509582123
      },
      "dragging": false
    },
    {
      "id": "openAIEmbeddings_0",
      "position": {
        "x": -1335.8789798535172,
        "y": -789.7367101791157
      },
      "type": "customNode",
      "data": {
        "id": "openAIEmbeddings_0",
        "label": "OpenAI Embeddings",
        "version": 4,
        "name": "openAIEmbeddings",
        "type": "OpenAIEmbeddings",
        "baseClasses": [
          "OpenAIEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "OpenAI API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAIEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "text-embedding-ada-002",
            "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
          },
          {
            "label": "Strip New Lines",
            "name": "stripNewLines",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-basepath-string"
          },
          {
            "label": "Dimensions",
            "name": "dimensions",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-dimensions-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "text-embedding-3-small",
          "stripNewLines": "",
          "batchSize": "",
          "timeout": "",
          "basepath": "",
          "dimensions": ""
        },
        "outputAnchors": [
          {
            "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "name": "openAIEmbeddings",
            "label": "OpenAIEmbeddings",
            "description": "OpenAI API to generate embeddings for a given text",
            "type": "OpenAIEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 424,
      "selected": false,
      "positionAbsolute": {
        "x": -1335.8789798535172,
        "y": -789.7367101791157
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-toolAgent_0-toolAgent_0-input-model-BaseChatModel"
    },
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-toolAgent_0-toolAgent_0-input-memory-BaseChatMemory"
    },
    {
      "source": "retrieverTool_0",
      "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool"
    },
    {
      "source": "openAIEmbeddings_0",
      "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
      "target": "pinecone_0",
      "targetHandle": "pinecone_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-pinecone_0-pinecone_0-input-embeddings-Embeddings"
    },
    {
      "source": "pinecone_0",
      "sourceHandle": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
      "target": "retrieverTool_0",
      "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
      "type": "buttonedge",
      "id": "pinecone_0-pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
    }
  ]
}